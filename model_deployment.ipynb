{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a61d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install snowflake-connector-python\n",
    "# ! pip install snowflake-sqlalchemy\n",
    "# ! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66acc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "# importing credentials\n",
    "from creds import ACCOUNT,USERNAME,PASSWORD\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65f4ac",
   "metadata": {},
   "source": [
    "### Deployment Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2b71c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to utils.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile utils.py -a\n",
    "\n",
    "\n",
    "\"\"\" DEPLOYMENT UITLITY FUNCTIONS\"\"\"\n",
    "\n",
    "\n",
    "# defining the function to verify the feautures of incoming data\n",
    "def check_create_model_features(data,features_lst):\n",
    "    temp = pd.DataFrame()\n",
    "    for col in features_lst:\n",
    "        if col in data.columns.tolist():\n",
    "            temp[col]=data[col]\n",
    "        else:\n",
    "            temp[col]=0\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32aefb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to utils.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile utils.py -a\n",
    "\n",
    "# defining a function to insert the predictions into the snowflake table\n",
    "def insert_predictions(data,connection,engine):\n",
    "    \n",
    "   # establishing the connection to the snowflake \n",
    "    conn = snowflake.connector.connect(\n",
    "    user=USERNAME,\n",
    "    password=PASSWORD,\n",
    "    account=ACCOUNT,\n",
    "    role='ACCOUNTADMIN',\n",
    "    warehouse='COMPUTE_WH',\n",
    "    database='HEALTH_DB',\n",
    "    schema='PUBLIC'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # creating the logging table\n",
    "    table = \"PREDICTION_LOGGING_TEST\"\n",
    "    table_creation_query =f\"\"\"\n",
    "                            CREATE TABLE IF NOT EXISTS {table} (\n",
    "                                CASE_ID STRING,\n",
    "                                HOSPITAL_CODE INT,\n",
    "                                HOSPITAL_TYPE_CODE STRING,\n",
    "                                CITY_CODE_HOSPITAL INT,\n",
    "                                HOSPITAL_REGION_CODE STRING,\n",
    "                                AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL INT,\n",
    "                                DEPARTMENT STRING,\n",
    "                                WARD_TYPE STRING,\n",
    "                                WARD_FACILITY_CODE STRING,\n",
    "                                BED_GRADE INT,\n",
    "                                PATIENTID STRING,\n",
    "                                CITY_CODE_PATIENT INT,\n",
    "                                TYPE_OF_ADMISSION STRING,\n",
    "                                SEVERITY_OF_ILLNESS STRING,\n",
    "                                VISITORS_WITH_PATIENT INT,\n",
    "                                AGE STRING,\n",
    "                                ADMISSION_DEPOSIT FLOAT,\n",
    "                                ADMISSION_DATE DATE,\n",
    "                                DISCHARGE_DATE DATE,\n",
    "                                ADMISSION_MONTH STRING,\n",
    "                                ADMISSION_DAY STRING,\n",
    "                                ADMISSION_ILLNESS STRING,\n",
    "                                ILLNESS_BEDGRADE STRING,\n",
    "                                DEPARTMENT_ILLNESS STRING,\n",
    "                                LOS INT,\n",
    "                                LOS_PREDICTED INT\n",
    "                            )\n",
    "                            \"\"\"\n",
    "    connection.execute(table_creation_query)\n",
    "    \n",
    "    # inserting the predictions to the table\n",
    "    write_pandas(conn, data, table_name=table)\n",
    "    return \"Success\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00d5b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to utils.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile utils.py -a\n",
    "\n",
    "\n",
    "# defining the function to send notofications via mail \n",
    "def send_mail(mail_string):\n",
    "   \n",
    "    subject = 'Patient LOS Prediction - STATUS MAIL'\n",
    "    mail_content = mail_string\n",
    "\n",
    "    username= MAIL_ID\n",
    "    password= MAIL_PASSWORD\n",
    "    send_from =MAIL_ID\n",
    "    send_to = MAIL_ID\n",
    "    Cc = ''\n",
    "    \n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = send_from\n",
    "    msg['To'] = send_to\n",
    "    msg['Cc'] = Cc\n",
    "    msg['Date'] = formatdate(localtime = True)\n",
    "    msg['Subject'] = subject\n",
    "    msg.attach(MIMEText(mail_content, 'plain'))\n",
    "    smtp = smtplib.SMTP('smtp.gmail.com',587)\n",
    "    smtp.ehlo()\n",
    "    smtp.starttls()\n",
    "    smtp.login(username,password)\n",
    "    smtp.sendmail(send_from, send_to.split(',') + msg['Cc'].split(','), msg.as_string())\n",
    "    smtp.quit()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656ad2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to utils.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile utils.py -a\n",
    "\n",
    "\n",
    "# defining the function for batch prediction and writing it to the snowflake table\n",
    "def deploy():\n",
    "        \n",
    "        # defining the query to load new test data from the simulation data\n",
    "        QUERY=\"\"\"\n",
    "\n",
    "        WITH BASE AS (\n",
    "\n",
    "            SELECT CASE_ID,\n",
    "                   COALESCE(HOSPITAL_CODE,0) AS HOSPITAL_CODE,\n",
    "                   COALESCE(HOSPITAL_TYPE_CODE,'None') AS HOSPITAL_TYPE_CODE,\n",
    "                   COALESCE(CITY_CODE_HOSPITAL,0) AS CITY_CODE_HOSPITAL,\n",
    "                   COALESCE(HOSPITAL_REGION_CODE,'None') AS HOSPITAL_REGION_CODE,\n",
    "                   COALESCE(AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,0) AS AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,\n",
    "                   COALESCE(DEPARTMENT,'None') AS DEPARTMENT,\n",
    "                   COALESCE(WARD_TYPE,'None') AS WARD_TYPE,\n",
    "                   COALESCE(WARD_FACILITY_CODE,'None') AS WARD_FACILITY_CODE,\n",
    "                   COALESCE(BED_GRADE,0) AS BED_GRADE,\n",
    "                   PATIENTID,\n",
    "                   COALESCE(CITY_CODE_PATIENT,0) AS CITY_CODE_PATIENT,\n",
    "                   COALESCE(TYPE_OF_ADMISSION,'None') AS TYPE_OF_ADMISSION,\n",
    "                   COALESCE(SEVERITY_OF_ILLNESS,'Minor') AS SEVERITY_OF_ILLNESS,\n",
    "                   COALESCE(VISITORS_WITH_PATIENT,0) AS VISITORS_WITH_PATIENT,\n",
    "                   COALESCE(AGE,'None') AS AGE,\n",
    "                   COALESCE(ADMISSION_DEPOSIT,0) AS ADMISSION_DEPOSIT,\n",
    "                   ADMISSION_DATE,\n",
    "                   DISCHARGE_DATE\n",
    "\n",
    "            FROM HEALTH_DB.PUBLIC.SIMULATION_DATA\n",
    "\n",
    "        ),\n",
    "\n",
    "        BASE_WITH_FEATURES AS (\n",
    "\n",
    "            SELECT *,\n",
    "                    MONTHNAME(ADMISSION_DATE) AS ADMISSION_MONTH,\n",
    "                    DAYNAME(ADMISSION_DATE) AS ADMISSION_DAY,    \n",
    "                    CONCAT(TYPE_OF_ADMISSION,'-',SEVERITY_OF_ILLNESS) AS ADMISSION_ILLNESS,\n",
    "                    CONCAT(SEVERITY_OF_ILLNESS,'-',BED_GRADE) AS ILLNESS_BEDGRADE,\n",
    "                    CONCAT(DEPARTMENT,'-',SEVERITY_OF_ILLNESS) AS DEPARTMENT_ILLNESS,\n",
    "                    DATEDIFF(day,ADMISSION_DATE,DISCHARGE_DATE) AS LOS\n",
    "            FROM BASE \n",
    "\n",
    "        )    \n",
    "        SELECT * FROM BASE_WITH_FEATURES WHERE ADMISSION_DATE=CURRENT_DATE-580\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # defining an empty list to store notification for each phases\n",
    "        mail_lst = []\n",
    "        \n",
    "\n",
    "\n",
    "        # Creating the connection engine (way 1)\n",
    "        engine = create_engine(URL(\n",
    "            account=ACCOUNT,\n",
    "            user= USERNAME,\n",
    "            password= PASSWORD,\n",
    "            role=\"ACCOUNTADMIN\",\n",
    "            warehouse=\"COMPUTE_WH\",\n",
    "            database=\"HEALTH_DB\",\n",
    "            schema=\"PUBLIC\"\n",
    "        ))\n",
    "\n",
    "        # Connecting to the DB and executing the query\n",
    "        with engine.connect() as conn:\n",
    "\n",
    "            # loading the test data\n",
    "            result = conn.execute(text(QUERY))\n",
    "            test_data = pd.DataFrame(result.fetchall())\n",
    "            test_data.columns = result.keys()\n",
    "            mail_lst.append(\"STEP-1: Successfully loaded the test data \")\n",
    "\n",
    "\n",
    "            # appplying the preprocessing steps\n",
    "            test_data.columns = [col.upper() for col in test_data.columns.tolist()]\n",
    "            test_preprocessed = preprocess_data(test_data)\n",
    "            mail_lst.append(\"STEP-2: Successfully applied the data preprocessing on test data \")\n",
    "\n",
    "            # applying the feature selection by calling the helper function to verify the feautures of incoming data\n",
    "            final_features = pd.read_pickle(\"artifacts/final_features.pkl\")\n",
    "            test_data_final = check_create_model_features(test_preprocessed,final_features)\n",
    "            mail_lst.append(\"STEP-3: Successfully applied the feature selection\")\n",
    "\n",
    "            # getting the predictions\n",
    "            model = xgboost.XGBRegressor()\n",
    "            model.load_model(\"artifacts/xgb.model\")\n",
    "            test_data_final['LOS_PREDICTED'] = np.ceil(model.predict(test_data_final))\n",
    "            mail_lst.append(\"STEP-4: Successfully got the predictions\")\n",
    "\n",
    "\n",
    "            # wrirting the dataframe into a table\n",
    "            test_data_final.reset_index(inplace=True)\n",
    "            predictions = test_data_final[['CASE_ID','LOS_PREDICTED']]\n",
    "            logs = pd.merge(test_data,test_data_final[['CASE_ID','LOS_PREDICTED']],on=\"CASE_ID\")\n",
    "            status = insert_predictions(logs,conn,engine)\n",
    "            mail_lst.append(\"STEP-5: Successfully wrote the predictions to snowflake table\")       \n",
    "\n",
    "            # creating the mail body and sending the notifications\n",
    "            mail_string = \",\\n\".join(map(str,mail_lst))\n",
    "            send_mail(mail_string)\n",
    "\n",
    "            print(status)\n",
    "            return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532119a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Successfully sent mails\n",
      "Success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import deploy\n",
    "deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e32b8a9",
   "metadata": {},
   "source": [
    "### Deployment Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57470714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import deploy\n",
    "\n",
    "# defining the timezone\n",
    "tz_ny = pytz.timezone('Asia/Kolkata')\n",
    "\n",
    "# defining the time of running\n",
    "schduled_time = [\"11:35\"]\n",
    "\n",
    "while True:\n",
    "    # getting the timestamp\n",
    "    now=datetime.now(tz_ny)\n",
    "    \n",
    "    # extracting hours,minute from the timestamp\n",
    "    hour = str(now.hour)\n",
    "    minute = str(now.minute)\n",
    "    \n",
    "    # formatting the current time\n",
    "    curr_time = f\"{hour}:{minute}\"\n",
    "    \n",
    "    if curr_time in schduled_time:\n",
    "        deploy()\n",
    "        break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61155986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
