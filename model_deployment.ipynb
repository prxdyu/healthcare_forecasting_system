{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a61d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install snowflake-connector-python\n",
    "# ! pip install snowflake-sqlalchemy\n",
    "# ! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66acc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65f4ac",
   "metadata": {},
   "source": [
    "### Deployment Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2b71c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to utils.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile utils.py -a\n",
    "\n",
    "\n",
    "\"\"\" DEPLOYMENT UITLITY FUNCTIONS\"\"\"\n",
    "\n",
    "\n",
    "# defining the function to verify the feautures of incoming data\n",
    "def check_create_model_features(data,features_lst):\n",
    "    temp = pd.DataFrame()\n",
    "    for col in features_lst:\n",
    "        if col in data.columns.tolist():\n",
    "            temp[col]=data[col]\n",
    "        else:\n",
    "            temp[col]=0\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32aefb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to utils.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile utils.py -a\n",
    "\n",
    "# defining a function to insert the predictions into the snowflake table\n",
    "def insert_predictions(data,connection,engine):\n",
    "    \n",
    "    # setting up the snowflake credits\n",
    "    ACCOUNT = \"qq49985.ap-southeast-1\"\n",
    "    USERNAME = \"prxdyu\"\n",
    "    PASSWORD = \"Gala2471xy\"\n",
    "    \n",
    "\n",
    "   # establishing the connection to the snowflake \n",
    "    conn = snowflake.connector.connect(\n",
    "    user=USERNAME,\n",
    "    password=PASSWORD,\n",
    "    account=ACCOUNT,\n",
    "    role='ACCOUNTADMIN',\n",
    "    warehouse='COMPUTE_WH',\n",
    "    database='HEALTH_DB',\n",
    "    schema='PUBLIC'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # creating the logging table\n",
    "    table = \"PREDICTION_LOGGING_TEST\"\n",
    "    table_creation_query =f\"\"\"\n",
    "                            CREATE TABLE IF NOT EXISTS {table} (\n",
    "                                CASE_ID STRING,\n",
    "                                HOSPITAL_CODE INT,\n",
    "                                HOSPITAL_TYPE_CODE STRING,\n",
    "                                CITY_CODE_HOSPITAL INT,\n",
    "                                HOSPITAL_REGION_CODE STRING,\n",
    "                                AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL INT,\n",
    "                                DEPARTMENT STRING,\n",
    "                                WARD_TYPE STRING,\n",
    "                                WARD_FACILITY_CODE STRING,\n",
    "                                BED_GRADE INT,\n",
    "                                PATIENTID STRING,\n",
    "                                CITY_CODE_PATIENT INT,\n",
    "                                TYPE_OF_ADMISSION STRING,\n",
    "                                SEVERITY_OF_ILLNESS STRING,\n",
    "                                VISITORS_WITH_PATIENT INT,\n",
    "                                AGE STRING,\n",
    "                                ADMISSION_DEPOSIT FLOAT,\n",
    "                                ADMISSION_DATE DATE,\n",
    "                                DISCHARGE_DATE DATE,\n",
    "                                ADMISSION_MONTH STRING,\n",
    "                                ADMISSION_DAY STRING,\n",
    "                                ADMISSION_ILLNESS STRING,\n",
    "                                ILLNESS_BEDGRADE STRING,\n",
    "                                DEPARTMENT_ILLNESS STRING,\n",
    "                                LOS INT,\n",
    "                                LOS_PREDICTED INT\n",
    "                            )\n",
    "                            \"\"\"\n",
    "    connection.execute(table_creation_query)\n",
    "    \n",
    "    # inserting the predictions to the table\n",
    "    write_pandas(conn, data, table_name=table)\n",
    "    return \"Success\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00d5b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to utils.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile utils.py -a\n",
    "\n",
    "\n",
    "# defining the function to send notofications via mail \n",
    "def send_mail(mail_string):\n",
    "   \n",
    "    subject = 'Patient LOS Prediction - STATUS MAIL'\n",
    "    mail_content = mail_string\n",
    "\n",
    "    username= \"pradyublog@gmail.com\"\n",
    "    password= \"guwafcljmrgtpymu\"\n",
    "    send_from = \"pradyublog@gmail.com\"\n",
    "    send_to = \"pradyublog@gmail.com\"\n",
    "    Cc = ''\n",
    "    \n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = send_from\n",
    "    msg['To'] = send_to\n",
    "    msg['Cc'] = Cc\n",
    "    msg['Date'] = formatdate(localtime = True)\n",
    "    msg['Subject'] = subject\n",
    "    msg.attach(MIMEText(mail_content, 'plain'))\n",
    "    smtp = smtplib.SMTP('smtp.gmail.com',587)\n",
    "    smtp.ehlo()\n",
    "    smtp.starttls()\n",
    "    smtp.login(username,password)\n",
    "    smtp.sendmail(send_from, send_to.split(',') + msg['Cc'].split(','), msg.as_string())\n",
    "    smtp.quit()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656ad2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to utils.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile utils.py -a\n",
    "\n",
    "\n",
    "# defining the function for batch prediction and writing it to the snowflake table\n",
    "def deploy():\n",
    "        \n",
    "        # defining the query to load new test data from the simulation data\n",
    "        QUERY=\"\"\"\n",
    "\n",
    "        WITH BASE AS (\n",
    "\n",
    "            SELECT CASE_ID,\n",
    "                   COALESCE(HOSPITAL_CODE,0) AS HOSPITAL_CODE,\n",
    "                   COALESCE(HOSPITAL_TYPE_CODE,'None') AS HOSPITAL_TYPE_CODE,\n",
    "                   COALESCE(CITY_CODE_HOSPITAL,0) AS CITY_CODE_HOSPITAL,\n",
    "                   COALESCE(HOSPITAL_REGION_CODE,'None') AS HOSPITAL_REGION_CODE,\n",
    "                   COALESCE(AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,0) AS AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,\n",
    "                   COALESCE(DEPARTMENT,'None') AS DEPARTMENT,\n",
    "                   COALESCE(WARD_TYPE,'None') AS WARD_TYPE,\n",
    "                   COALESCE(WARD_FACILITY_CODE,'None') AS WARD_FACILITY_CODE,\n",
    "                   COALESCE(BED_GRADE,0) AS BED_GRADE,\n",
    "                   PATIENTID,\n",
    "                   COALESCE(CITY_CODE_PATIENT,0) AS CITY_CODE_PATIENT,\n",
    "                   COALESCE(TYPE_OF_ADMISSION,'None') AS TYPE_OF_ADMISSION,\n",
    "                   COALESCE(SEVERITY_OF_ILLNESS,'Minor') AS SEVERITY_OF_ILLNESS,\n",
    "                   COALESCE(VISITORS_WITH_PATIENT,0) AS VISITORS_WITH_PATIENT,\n",
    "                   COALESCE(AGE,'None') AS AGE,\n",
    "                   COALESCE(ADMISSION_DEPOSIT,0) AS ADMISSION_DEPOSIT,\n",
    "                   ADMISSION_DATE,\n",
    "                   DISCHARGE_DATE\n",
    "\n",
    "            FROM HEALTH_DB.PUBLIC.SIMULATION_DATA\n",
    "\n",
    "        ),\n",
    "\n",
    "        BASE_WITH_FEATURES AS (\n",
    "\n",
    "            SELECT *,\n",
    "                    MONTHNAME(ADMISSION_DATE) AS ADMISSION_MONTH,\n",
    "                    DAYNAME(ADMISSION_DATE) AS ADMISSION_DAY,    \n",
    "                    CONCAT(TYPE_OF_ADMISSION,'-',SEVERITY_OF_ILLNESS) AS ADMISSION_ILLNESS,\n",
    "                    CONCAT(SEVERITY_OF_ILLNESS,'-',BED_GRADE) AS ILLNESS_BEDGRADE,\n",
    "                    CONCAT(DEPARTMENT,'-',SEVERITY_OF_ILLNESS) AS DEPARTMENT_ILLNESS,\n",
    "                    DATEDIFF(day,ADMISSION_DATE,DISCHARGE_DATE) AS LOS\n",
    "            FROM BASE \n",
    "\n",
    "        )    \n",
    "        SELECT * FROM BASE_WITH_FEATURES WHERE ADMISSION_DATE=CURRENT_DATE-580\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # defining an empty list to store notification for each phases\n",
    "        mail_lst = []\n",
    "        \n",
    "        # creating an engine\n",
    "        ACCOUNT = \"qq49985.ap-southeast-1\"\n",
    "        USERNAME = \"prxdyu\"\n",
    "        PASSWORD = \"Gala2471xy\"\n",
    "\n",
    "\n",
    "        # Creating the connection engine (way 1)\n",
    "        engine = create_engine(URL(\n",
    "            account=ACCOUNT,\n",
    "            user= USERNAME,\n",
    "            password= PASSWORD,\n",
    "            role=\"ACCOUNTADMIN\",\n",
    "            warehouse=\"COMPUTE_WH\",\n",
    "            database=\"HEALTH_DB\",\n",
    "            schema=\"PUBLIC\"\n",
    "        ))\n",
    "\n",
    "        # Connecting to the DB and executing the query\n",
    "        with engine.connect() as conn:\n",
    "\n",
    "            # loading the test data\n",
    "            result = conn.execute(text(QUERY))\n",
    "            test_data = pd.DataFrame(result.fetchall())\n",
    "            test_data.columns = result.keys()\n",
    "            mail_lst.append(\"STEP-1: Successfully loaded the test data \")\n",
    "\n",
    "\n",
    "            # appplying the preprocessing steps\n",
    "            test_data.columns = [col.upper() for col in test_data.columns.tolist()]\n",
    "            test_preprocessed = preprocess_data(test_data)\n",
    "            mail_lst.append(\"STEP-2: Successfully applied the data preprocessing on test data \")\n",
    "\n",
    "            # applying the feature selection by calling the helper function to verify the feautures of incoming data\n",
    "            final_features = pd.read_pickle(\"artifacts/final_features.pkl\")\n",
    "            test_data_final = check_create_model_features(test_preprocessed,final_features)\n",
    "            mail_lst.append(\"STEP-3: Successfully applied the feature selection\")\n",
    "\n",
    "            # getting the predictions\n",
    "            model = xgboost.XGBRegressor()\n",
    "            model.load_model(\"artifacts/xgb.model\")\n",
    "            test_data_final['LOS_PREDICTED'] = np.ceil(model.predict(test_data_final))\n",
    "            mail_lst.append(\"STEP-4: Successfully got the predictions\")\n",
    "\n",
    "\n",
    "            # wrirting the dataframe into a table\n",
    "            test_data_final.reset_index(inplace=True)\n",
    "            predictions = test_data_final[['CASE_ID','LOS_PREDICTED']]\n",
    "            logs = pd.merge(test_data,test_data_final[['CASE_ID','LOS_PREDICTED']],on=\"CASE_ID\")\n",
    "            status = insert_predictions(logs,conn,engine)\n",
    "            mail_lst.append(\"STEP-5: Successfully wrote the predictions to snowflake table\")       \n",
    "\n",
    "            # creating the mail body and sending the notifications\n",
    "            mail_string = \",\\n\".join(map(str,mail_lst))\n",
    "            send_mail(mail_string)\n",
    "\n",
    "            print(status)\n",
    "            return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532119a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Successfully sent mails\n",
      "Success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import deploy\n",
    "deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e32b8a9",
   "metadata": {},
   "source": [
    "### Deployment Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57470714",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[06:05:04] /workspace/dmlc-core/src/io/local_filesys.cc:210: Check failed: allow_null:  LocalFileSystem::Open \"artifcats/xgb.model\": No such file or directory\nStack trace:\n  [bt] (0) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x1705ee) [0x7f44a3add5ee]\n  [bt] (1) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x8f687b) [0x7f44a426387b]\n  [bt] (2) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x8e08ae) [0x7f44a424d8ae]\n  [bt] (3) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterLoadModel+0x1bb) [0x7f44a39fd49b]\n  [bt] (4) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f44f890fa4a]\n  [bt] (5) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f44f890efea]\n  [bt] (6) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x12461) [0x7f44f8892461]\n  [bt] (7) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x86eb) [0x7f44f88886eb]\n  [bt] (8) /home/ec2-user/anaconda3/envs/python3/bin/python(_PyObject_MakeTpCall+0x26b) [0x5588e0e1aa6b]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m curr_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhour\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminute\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m curr_time \u001b[38;5;129;01min\u001b[39;00m schduled_time:\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/SageMaker/utils.py:279\u001b[0m, in \u001b[0;36mdeploy\u001b[0;34m()\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# getting the predictions\u001b[39;00m\n\u001b[1;32m    278\u001b[0m model \u001b[38;5;241m=\u001b[39m xgboost\u001b[38;5;241m.\u001b[39mXGBRegressor()\n\u001b[0;32m--> 279\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43martifcats/xgb.model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m test_data_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOS_PREDICTED\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mceil(model\u001b[38;5;241m.\u001b[39mpredict(test_data_final))\n\u001b[1;32m    281\u001b[0m mail_lst\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTEP-4: Successfully got the predictions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/sklearn.py:915\u001b[0m, in \u001b[0;36mXGBModel.load_model\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__():\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m Booster({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs})\n\u001b[0;32m--> 915\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m meta_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster()\u001b[38;5;241m.\u001b[39mattr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit_learn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:2705\u001b[0m, in \u001b[0;36mBooster.load_model\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[1;32m   2702\u001b[0m     \u001b[38;5;66;03m# assume file name, cannot use os.path.exist to check, file can be\u001b[39;00m\n\u001b[1;32m   2703\u001b[0m     \u001b[38;5;66;03m# from URL.\u001b[39;00m\n\u001b[1;32m   2704\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname))\n\u001b[0;32m-> 2705\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterLoadModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2706\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mbytearray\u001b[39m):\n\u001b[1;32m   2707\u001b[0m     buf \u001b[38;5;241m=\u001b[39m fname\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:296\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [06:05:04] /workspace/dmlc-core/src/io/local_filesys.cc:210: Check failed: allow_null:  LocalFileSystem::Open \"artifcats/xgb.model\": No such file or directory\nStack trace:\n  [bt] (0) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x1705ee) [0x7f44a3add5ee]\n  [bt] (1) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x8f687b) [0x7f44a426387b]\n  [bt] (2) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x8e08ae) [0x7f44a424d8ae]\n  [bt] (3) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterLoadModel+0x1bb) [0x7f44a39fd49b]\n  [bt] (4) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f44f890fa4a]\n  [bt] (5) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f44f890efea]\n  [bt] (6) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x12461) [0x7f44f8892461]\n  [bt] (7) /home/ec2-user/anaconda3/envs/python3/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x86eb) [0x7f44f88886eb]\n  [bt] (8) /home/ec2-user/anaconda3/envs/python3/bin/python(_PyObject_MakeTpCall+0x26b) [0x5588e0e1aa6b]\n\n"
     ]
    }
   ],
   "source": [
    "from utils import deploy\n",
    "\n",
    "# defining the timezone\n",
    "tz_ny = pytz.timezone('Asia/Kolkata')\n",
    "\n",
    "# defining the time of running\n",
    "schduled_time = [\"11:35\"]\n",
    "\n",
    "while True:\n",
    "    # getting the timestamp\n",
    "    now=datetime.now(tz_ny)\n",
    "    \n",
    "    # extracting hours,minute from the timestamp\n",
    "    hour = str(now.hour)\n",
    "    minute = str(now.minute)\n",
    "    \n",
    "    # formatting the current time\n",
    "    curr_time = f\"{hour}:{minute}\"\n",
    "    \n",
    "    if curr_time in schduled_time:\n",
    "        deploy()\n",
    "        break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e7efe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive\t\t      model_deployment.ipynb\t\t __pycache__\r\n",
      "artifacts\t      model_monitoring.ipynb\t\t retraining_artifacts\r\n",
      "lost+found\t      model_monitoring_retraining.ipynb  rough.ipynb\r\n",
      "model_building.ipynb  model_retraining.ipynb\t\t utils.py\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "349fa010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive\t\t      model_deployment.ipynb\t\t __pycache__\r\n",
      "artifacts\t      model_monitoring.ipynb\t\t retraining_artifacts\r\n",
      "lost+found\t      model_monitoring_retraining.ipynb  rough.ipynb\r\n",
      "model_building.ipynb  model_retraining.ipynb\t\t utils.py\r\n"
     ]
    }
   ],
   "source": [
    "! cd artifacts \n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73490b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026ef67",
   "metadata": {},
   "source": [
    "['WARD_TYPE_P', 'ADMISSION_DAY_Sat', 'ADMISSION_DEPOSIT', 'BED_GRADE_2', 'ADMISSION_MONTH_Oct', 'AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL', 'WARD_TYPE_S', 'ILLNESS_BEDGRADE_Moderate-2', 'ADMISSION_MONTH_Nov', 'DEPARTMENT_ILLNESS_gynecology-Extreme', 'CITY_CODE_PATIENT_8', 'CITY_CODE_HOSPITAL_7', 'ADMISSION_DAY_Tue', 'AGE_31-40', 'AGE_41-50', 'ADMISSION_DAY_Mon', 'AGE_51-60', 'ADMISSION_DAY_Thu', 'TYPE_OF_ADMISSION_Trauma', 'SEVERITY_OF_ILLNESS_Minor', 'ADMISSION_DAY_Wed', 'ADMISSION_DAY_Sun', 'VISITORS_WITH_PATIENT', 'TYPE_OF_ADMISSION_Emergency', 'WARD_TYPE_Q', 'DEPARTMENT_ILLNESS_gynecology-Moderate', 'CITY_CODE_HOSPITAL_2', 'ILLNESS_BEDGRADE_Extreme-1']\n",
    "\n",
    "\n",
    "['WARD_TYPE_Q', 'AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL', 'ADMISSION_DAY_Tue', 'VISITORS_WITH_PATIENT', 'TYPE_OF_ADMISSION_Trauma', 'ADMISSION_DAY_Sat', 'ADMISSION_DAY_Wed', 'WARD_TYPE_P', 'CITY_CODE_PATIENT_8', 'WARD_TYPE_S', 'AGE_41-50', 'TYPE_OF_ADMISSION_Emergency', 'ADMISSION_DAY_Thu', 'AGE_31-40', 'BED_GRADE_2', 'ADMISSION_MONTH_Oct', 'SEVERITY_OF_ILLNESS_Minor', 'AGE_51-60', 'CITY_CODE_HOSPITAL_2', 'ADMISSION_DAY_Sun', 'ADMISSION_DEPOSIT', 'CITY_CODE_HOSPITAL_7', 'ILLNESS_BEDGRADE_Extreme-1', 'ADMISSION_DAY_Mon', 'ADMISSION_MONTH_Nov', 'DEPARTMENT_ILLNESS_gynecology-Extreme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a251e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = ['WARD_TYPE_P', 'ADMISSION_DAY_Sat', 'ADMISSION_DEPOSIT', 'BED_GRADE_2', 'ADMISSION_MONTH_Oct', 'AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL', 'WARD_TYPE_S', 'ILLNESS_BEDGRADE_Moderate-2', 'ADMISSION_MONTH_Nov', 'DEPARTMENT_ILLNESS_gynecology-Extreme', 'CITY_CODE_PATIENT_8', 'CITY_CODE_HOSPITAL_7', 'ADMISSION_DAY_Tue', 'AGE_31-40', 'AGE_41-50', 'ADMISSION_DAY_Mon', 'AGE_51-60', 'ADMISSION_DAY_Thu', 'TYPE_OF_ADMISSION_Trauma', 'SEVERITY_OF_ILLNESS_Minor', 'ADMISSION_DAY_Wed', 'ADMISSION_DAY_Sun', 'VISITORS_WITH_PATIENT', 'TYPE_OF_ADMISSION_Emergency', 'WARD_TYPE_Q', 'DEPARTMENT_ILLNESS_gynecology-Moderate', 'CITY_CODE_HOSPITAL_2', 'ILLNESS_BEDGRADE_Extreme-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2aa7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = ['WARD_TYPE_Q', 'AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL', 'ADMISSION_DAY_Tue', 'VISITORS_WITH_PATIENT', 'TYPE_OF_ADMISSION_Trauma', 'ADMISSION_DAY_Sat', 'ADMISSION_DAY_Wed', 'WARD_TYPE_P', 'CITY_CODE_PATIENT_8', 'WARD_TYPE_S', 'AGE_41-50', 'TYPE_OF_ADMISSION_Emergency', 'ADMISSION_DAY_Thu', 'AGE_31-40', 'BED_GRADE_2', 'ADMISSION_MONTH_Oct', 'SEVERITY_OF_ILLNESS_Minor', 'AGE_51-60', 'CITY_CODE_HOSPITAL_2', 'ADMISSION_DAY_Sun', 'ADMISSION_DEPOSIT', 'CITY_CODE_HOSPITAL_7', 'ILLNESS_BEDGRADE_Extreme-1', 'ADMISSION_DAY_Mon', 'ADMISSION_MONTH_Nov', 'DEPARTMENT_ILLNESS_gynecology-Extreme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9e9592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(a1)==set(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8687ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DEPARTMENT_ILLNESS_gynecology-Moderate', 'ILLNESS_BEDGRADE_Moderate-2'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(a1).difference(set(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e216d8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(a1).difference(set(a1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61155986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
